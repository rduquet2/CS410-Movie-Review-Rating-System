{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dict()\n",
    "train['positive'] = []\n",
    "train['negative'] = []\n",
    "with open('IMDB Dataset.csv', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for review_sentiment in reader:\n",
    "        review = review_sentiment[0]\n",
    "        review = review.lower()\n",
    "        review = re.sub(r'[^a-z\\s]', '', review)\n",
    "        review = re.sub(r'\\s+', ' ', review)\n",
    "        review = review.split()\n",
    "        sentiment = review_sentiment[1]\n",
    "        train[sentiment].append(review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FREQUENCY TABLE\n",
    "frequencies = dict()\n",
    "for class_name, texts in train.items():\n",
    "    bigram_tokens = []\n",
    "    for text in texts:\n",
    "        for i in range(len(text)-1):\n",
    "            bigram_tokens.append(text[i] + \" \" + text[i+1])\n",
    "    frequencies[class_name] = Counter(bigram_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE STOPWORDS FROM TABLE\n",
    "stop_words = set(stopwords.words('english'))\n",
    "cleaned_frequencies = {}\n",
    "for class_name, counts in frequencies.items():\n",
    "    cleaned_frequencies[class_name] = Counter()\n",
    "    for bigram, count in counts.items():\n",
    "        token_pair = bigram.split(\" \")\n",
    "        if (token_pair[0] not in stop_words or token_pair[1] not in stop_words):\n",
    "            cleaned_frequencies[class_name][bigram] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOOTH THE FREQUENCIES USING LAPLACE\n",
    "smoothing_constant = 0.01\n",
    "likelihood = {}\n",
    "for class_name, counts in cleaned_frequencies.items():\n",
    "    likelihood[class_name] = {}\n",
    "    count_total = sum(counts.values())\n",
    "    for bigram, count in counts.items():\n",
    "        likelihood[class_name][bigram] = (count+smoothing_constant)/(count_total + (smoothing_constant*(len(counts)+1)))\n",
    "    likelihood[class_name]['OOV'] = smoothing_constant/(count_total + (smoothing_constant*(len(counts)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFY A REVIEW\n",
    "def classify(review, likelihood, prior):\n",
    "    pos_total = np.log(prior)\n",
    "    neg_total = np.log(1-prior)\n",
    "    for k in range(len(text)-1):\n",
    "        if (text[k] not in stop_words or text[k+1] not in stop_words):\n",
    "            if ((text[k] + \" \" + text[k+1]) in likelihood[\"positive\"]):\n",
    "                pos_total += np.log(likelihood[\"positive\"][text[k] + \" \" + text[k+1]])\n",
    "            else:\n",
    "                pos_total += np.log(likelihood[\"positive\"][\"OOV\"])\n",
    "            if ((text[k] + \" \" + text[k+1]) in likelihood[\"negative\"]):\n",
    "                neg_total += np.log(likelihood[\"negative\"][text[k] + \" \" + text[k+1]])\n",
    "            else:\n",
    "                neg_total += np.log(likelihood[\"negative\"][\"OOV\"])\n",
    "    if (pos_total > neg_total):\n",
    "        return (\"Positive\", pos_total, neg_total)\n",
    "    else:\n",
    "        return (\"Negative\", pos_total, neg_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Negative', -1260.0778418740128, -1179.8617773048038)\n"
     ]
    }
   ],
   "source": [
    "review = \"For anyone with a hunger for real science fiction rather than the crowd-pleasing, watered-down version Hollywood typically offers (and that I often enjoy immensely), Interstellar is a satisfying entrÃ©e. I'd rank this alongside Memento and The Dark Knight as the best Nolan has done, and it's an immediate contender for one of 2014's best. The film deserves the label of an experience and the bigger the venue, the more immersive it will be. As event movies go, this is one of the most unique and mesmerizing.\"\n",
    "print(classify(review, likelihood=likelihood, prior=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We do not recommend this movie\n",
      "Approximately 0.0% of this movie's reviews had positive sentiment\n"
     ]
    }
   ],
   "source": [
    "reviews = [\"Hello World\"]\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for r1 in reviews:\n",
    "    if (classify(r1, likelihood, prior = 0.5)[0] == \"Positive\"):\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        neg_count += 1\n",
    "if (pos_count/(pos_count+neg_count) > 0.85):\n",
    "    print(\"We recommend this movie!\")\n",
    "else:\n",
    "    print(\"We do not recommend this movie\")\n",
    "print(f'Approximately {(pos_count/(pos_count+neg_count)) * 100}% of this movie\\'s reviews had positive sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
